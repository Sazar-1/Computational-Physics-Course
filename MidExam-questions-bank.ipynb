{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1408d1ac-7285-4ff5-9f6f-71783a318131",
   "metadata": {},
   "source": [
    "\n",
    "# **Computational Physics Exam**  \n",
    "**Duration:** 2 hours  \n",
    "**Total Marks:** 100  \n",
    "\n",
    "---\n",
    "\n",
    "## **Section A: Multiple Choice Questions** (20 Marks)  \n",
    "**Instructions:** Choose the correct answer for each question. Each question carries 2 marks.  \n",
    "\n",
    "1. Which NumPy function is used to create an array of evenly spaced numbers?  \n",
    "   a) `np.linspace()`  \n",
    "   b) `np.arange()`  \n",
    "   c) `np.ones()`  \n",
    "   d) `np.zeros()`  \n",
    "\n",
    "2. In numerical differentiation, the central difference method is more accurate than the forward difference method because:  \n",
    "   a) It uses only one point  \n",
    "   b) It uses two points symmetrically around the point of interest  \n",
    "   c) It ignores higher-order terms  \n",
    "   d) It is computationally cheaper  \n",
    "\n",
    "3. Which SciPy function is used to solve a system of linear equations $Ax = b$?  \n",
    "   a) `scipy.integrate.solve()`  \n",
    "   b) `scipy.linalg.solve()`  \n",
    "   c) `scipy.optimize.root()`  \n",
    "   d) `scipy.interpolate.spline()`  \n",
    "\n",
    "4. The trapezoidal rule for numerical integration is:  \n",
    "   a) Exact for linear functions  \n",
    "   b) Exact for quadratic functions  \n",
    "   c) Exact for cubic functions  \n",
    "   d) Exact for exponential functions  \n",
    "\n",
    "5. Which Matplotlib function is used to create a 2D line plot?  \n",
    "   a) `plt.scatter()`  \n",
    "   b) `plt.plot()`  \n",
    "   c) `plt.bar()`  \n",
    "   d) `plt.hist()`  \n",
    "\n",
    "6. The Euler method for solving first-order ODEs is:  \n",
    "   a) A second-order accurate method  \n",
    "   b) A first-order accurate method  \n",
    "   c) Unconditionally stable  \n",
    "   d) Only applicable to nonlinear ODEs  \n",
    "\n",
    "7. Which NumPy function computes the dot product of two arrays?  \n",
    "   a) `np.dot()`  \n",
    "   b) `np.cross()`  \n",
    "   c) `np.matmul()`  \n",
    "   d) `np.inner()`  \n",
    "\n",
    "8. The `scipy.integrate.solve_ivp` function is used to:  \n",
    "   a) Solve linear systems  \n",
    "   b) Perform numerical integration of ODEs  \n",
    "   c) Compute eigenvalues  \n",
    "   d) Fit data to a curve  \n",
    "\n",
    "9. The Simpson’s rule for numerical integration requires:  \n",
    "   a) An odd number of points  \n",
    "   b) An even number of points  \n",
    "   c) Only two points  \n",
    "   d) Equally spaced points  \n",
    "\n",
    "10. Which of the following is **not** a method for solving ODEs?  \n",
    "    a) Runge-Kutta  \n",
    "    b) Finite difference  \n",
    "    c) Euler  \n",
    "    d) Gauss-Seidel  \n",
    "\n",
    "---\n",
    "\n",
    "## **Section B: Short Answer Questions** (30 Marks)  \n",
    "**Instructions:** Answer all questions. Each question carries 5 marks.  \n",
    "\n",
    "11. Write a Python code snippet using NumPy to compute the derivative of $ f(x) = x^2 $ at $ x = 2 $ using the central difference method.  \n",
    "\n",
    "12. Explain the difference between `np.linspace(0, 10, 5)` and `np.arange(0, 10, 2)`.  \n",
    "\n",
    "13. Write the formula for the trapezoidal rule for numerical integration and explain why it is an approximation.  \n",
    "\n",
    "14. Given the linear system:  \n",
    "   $$\n",
    "   2x + 3y = 5 \\\\\n",
    "   4x + y = 6\n",
    "   $$  \n",
    "   Write a Python code using SciPy to solve for $x$ and $y$.  \n",
    "\n",
    "15. Describe the Euler method for solving a first-order ODE and list one advantage and one disadvantage.  \n",
    "\n",
    "16. Write a Python code using Matplotlib to plot the function $ f(x) = \\sin(x) $ for $ x \\in [0, 2\\pi] $ with labeled axes and a title.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Section C: Programming Problems** (50 Marks)  \n",
    "**Instructions:** Write complete Python programs to solve the following problems.  \n",
    "\n",
    "17. **(15 Marks)**  \n",
    "   Write a Python program to compute the integral of $ f(x) = e^{-x^2} $ from $0$ to $1$ using:  \n",
    "   - The trapezoidal rule  \n",
    "   - Simpson’s rule  \n",
    "   Compare the results with the exact value (approximate exact value: 0.7468).  \n",
    "\n",
    "18. **(15 Marks)**  \n",
    "   Solve the first-order ODE:  \n",
    "   $$\n",
    "   \\frac{dy}{dt} = -2y, \\quad y(0) = 1\n",
    "   $$  \n",
    "   using the **Euler method** and the **4th-order Runge-Kutta method** over $ t \\in [0, 2] $ with a step size of $ h = 0.1 $. Plot both solutions along with the exact solution $ y(t) = e^{-2t} $.  \n",
    "\n",
    "19. **(20 Marks)**  \n",
    "   Given the system of equations:  \n",
    "   $$\n",
    "   3x + 2y - z = 1 \n",
    "   $$\n",
    "   $$\n",
    "   2x - 2y + 4z = -2 \n",
    "   $$\n",
    "\n",
    "$$\n",
    "   -x + 0.5y - z = 0\n",
    "   $$  \n",
    "   - Solve the system using **Gaussian elimination** (without pivoting) implemented in NumPy.  \n",
    "   - Verify your solution using `scipy.linalg.solve()`.  \n",
    "   - Compute the determinant and condition number of the coefficient matrix.  \n",
    "\n",
    "---\n",
    "# **Additional Exam Questions on Curve Fitting and Root Finding**  \n",
    "\n",
    "## **Section D: Curve Fitting and Root Finding** (30 Marks)  \n",
    "\n",
    "### **Multiple Choice Questions** (10 Marks)  \n",
    "**Instructions:** Choose the correct answer. Each question carries 2 marks.  \n",
    "\n",
    "1. Which SciPy function is used for least-squares curve fitting?  \n",
    "   a) `scipy.optimize.curve_fit()`  \n",
    "   b) `scipy.interpolate.fit()`  \n",
    "   c) `scipy.stats.linregress()`  \n",
    "   d) `scipy.signal.find_peaks()`  \n",
    "\n",
    "2. The Newton-Raphson method for root finding requires:  \n",
    "   a) Only the function value  \n",
    "   b) The function value and its first derivative  \n",
    "   c) The function value and its second derivative  \n",
    "   d) No derivative information  \n",
    "\n",
    "3. Which method is **not** used for finding roots of a function?  \n",
    "   a) Bisection method  \n",
    "   b) Secant method  \n",
    "   c) Trapezoidal rule  \n",
    "   d) Brent’s method  \n",
    "\n",
    "4. Polynomial fitting using `np.polyfit()` returns:  \n",
    "   a) The roots of the polynomial  \n",
    "   b) The coefficients of the polynomial  \n",
    "   c) The derivative of the polynomial  \n",
    "   d) The integral of the polynomial  \n",
    "\n",
    "5. The `scipy.optimize.root()` function can use which of the following methods?  \n",
    "   a) `'hybr'` (hybrid method)  \n",
    "   b) `'lm'` (Levenberg-Marquardt)  \n",
    "   c) `'bfgs'` (quasi-Newton method)  \n",
    "   d) All of the above  \n",
    "\n",
    "---\n",
    "\n",
    "### **Short Answer Questions** (10 Marks)  \n",
    "**Instructions:** Answer all questions. Each question carries 5 marks.  \n",
    "\n",
    "6. **Curve Fitting:**  \n",
    "   Given the following data:  \n",
    "   ```\n",
    "   x = [0, 1, 2, 3, 4]  \n",
    "   y = [1.0, 1.8, 3.3, 4.5, 6.2]  \n",
    "   ```\n",
    "   Write a Python script to fit a linear model $ y = mx + c $ using `scipy.optimize.curve_fit()` and plot the best-fit line along with the data points.  \n",
    "\n",
    "7. **Root Finding:**  \n",
    "   Explain the **Bisection method** for finding roots and list one advantage and one disadvantage.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Programming Problem** (10 Marks)  \n",
    "\n",
    "8. **Finding Roots of a Nonlinear Equation**  \n",
    "   Find the root of the equation:  \n",
    "   $$\n",
    "   f(x) = x^3 - 2x - 5\n",
    "   $$  \n",
    "   using:  \n",
    "   - The **Newton-Raphson method** (initial guess $ x_0 = 2 $).  \n",
    "   - The **Bisection method** (interval $[1, 3]$).  \n",
    "   Compare the results and print the number of iterations required for each method.  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**End of Exam**  \n",
    "**Good Luck!**  \n",
    "\n",
    "---\n",
    "\n",
    "### **Marking Scheme:**  \n",
    "- **Section A:** 2 marks per correct answer.  \n",
    "- **Section B:** 5 marks per question (partial credit for correct reasoning).  \n",
    "- **Section C:**  \n",
    "  - **Q17:** Correct implementation (10), comparison and analysis (5).  \n",
    "  - **Q18:** Correct Euler & RK4 implementation (10), plotting (5).  \n",
    "  - **Q19:** Correct Gaussian elimination (8), SciPy solution (4), matrix analysis (8).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc63444-0d1d-40f6-ae5b-5bbd727a1645",
   "metadata": {},
   "source": [
    "# **Computational Physics Exam – Answer Key**  \n",
    "\n",
    "## **Section A: Multiple Choice Questions** (20 Marks)  \n",
    "1. **a) `np.linspace()`**  \n",
    "2. **b) It uses two points symmetrically around the point of interest**  \n",
    "3. **b) `scipy.linalg.solve()`**  \n",
    "4. **a) Exact for linear functions**  \n",
    "5. **b) `plt.plot()`**  \n",
    "6. **b) A first-order accurate method**  \n",
    "7. **a) `np.dot()`**  \n",
    "8. **b) Perform numerical integration of ODEs**  \n",
    "9. **a) An odd number of points**  \n",
    "10. **d) Gauss-Seidel**  \n",
    "\n",
    "---\n",
    "\n",
    "## **Section B: Short Answer Questions** (30 Marks)  \n",
    "\n",
    "### **11. Central Difference Derivative of $ f(x) = x^2 $ at $ x = 2 $**  \n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    return x ** 2\n",
    "\n",
    "x = 2\n",
    "h = 0.0001  # Small step size\n",
    "derivative = (f(x + h) - f(x - h)) / (2 * h)\n",
    "print(derivative)  # Expected: ~4.0\n",
    "```\n",
    "\n",
    "### **12. Difference between `np.linspace(0, 10, 5)` and `np.arange(0, 10, 2)`**  \n",
    "- `np.linspace(0, 10, 5)` generates **5 evenly spaced numbers** between 0 and 10 (inclusive): `[0, 2.5, 5, 7.5, 10]`.  \n",
    "- `np.arange(0, 10, 2)` generates numbers from 0 to 10 (exclusive) with a step of 2: `[0, 2, 4, 6, 8]`.  \n",
    "\n",
    "### **13. Trapezoidal Rule Formula and Approximation**  \n",
    "The trapezoidal rule is:  \n",
    "$$\n",
    "\\int_{a}^{b} f(x) \\, dx \\approx \\frac{h}{2} \\left[ f(x_0) + 2f(x_1) + 2f(x_2) + \\dots + f(x_n) \\right]\n",
    "$$  \n",
    "It approximates the integral by summing trapezoids under the curve, which is exact for linear functions but approximate for higher-order functions.  \n",
    "\n",
    "### **14. Solving Linear System with SciPy**  \n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.linalg import solve\n",
    "\n",
    "A = np.array([[2, 3], [4, 1]])\n",
    "b = np.array([5, 6])\n",
    "x = solve(A, b)\n",
    "print(x)  # Solution: x = 1.3, y = 0.8\n",
    "```\n",
    "\n",
    "### **15. Euler Method for ODEs**  \n",
    "- **Method:**  \n",
    "  $$\n",
    "  y_{n+1} = y_n + h \\cdot f(t_n, y_n)\n",
    "  $$  \n",
    "- **Advantage:** Simple to implement.  \n",
    "- **Disadvantage:** Low accuracy (first-order).  \n",
    "\n",
    "### **16. Plotting $ f(x) = \\sin(x) $ with Matplotlib**  \n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "plt.plot(x, y, label='sin(x)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Plot of sin(x)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Section C: Programming Problems** (50 Marks)  \n",
    "\n",
    "### **17. Numerical Integration of $ f(x) = e^{-x^2} $**\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.integrate import trapezoid, simpson\n",
    "\n",
    "def f(x):\n",
    "    return np.exp(-x**2)\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "y = f(x)\n",
    "\n",
    "trapz_result = trapezoid(y, x)\n",
    "simpson_result = simpson(y, x)\n",
    "\n",
    "print(\"Trapezoidal Rule:\", trapz_result)  # ~0.7468\n",
    "print(\"Simpson's Rule:\", simpson_result)   # More accurate\n",
    "```\n",
    "\n",
    "### **18. Solving ODE $ \\frac{dy}{dt} = -2y $ with Euler & RK4**  \n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(t, y):\n",
    "    return -2 * y\n",
    "\n",
    "# Exact solution\n",
    "def exact(t):\n",
    "    return np.exp(-2 * t)\n",
    "\n",
    "# Euler method\n",
    "def euler(f, y0, t_span, h):\n",
    "    t = np.arange(t_span[0], t_span[1] + h, h)\n",
    "    y = np.zeros(len(t))\n",
    "    y[0] = y0\n",
    "    for i in range(1, len(t)):\n",
    "        y[i] = y[i-1] + h * f(t[i-1], y[i-1])\n",
    "    return t, y\n",
    "\n",
    "# RK4 method\n",
    "def rk4(f, y0, t_span, h):\n",
    "    t = np.arange(t_span[0], t_span[1] + h, h)\n",
    "    y = np.zeros(len(t))\n",
    "    y[0] = y0\n",
    "    for i in range(1, len(t)):\n",
    "        k1 = h * f(t[i-1], y[i-1])\n",
    "        k2 = h * f(t[i-1] + h/2, y[i-1] + k1/2)\n",
    "        k3 = h * f(t[i-1] + h/2, y[i-1] + k2/2)\n",
    "        k4 = h * f(t[i-1] + h, y[i-1] + k3)\n",
    "        y[i] = y[i-1] + (k1 + 2*k2 + 2*k3 + k4) / 6\n",
    "    return t, y\n",
    "\n",
    "# Solve and plot\n",
    "t_span = [0, 2]\n",
    "h = 0.1\n",
    "y0 = 1\n",
    "\n",
    "t_euler, y_euler = euler(f, y0, t_span, h)\n",
    "t_rk4, y_rk4 = rk4(f, y0, t_span, h)\n",
    "t_exact = np.linspace(0, 2, 100)\n",
    "y_exact = exact(t_exact)\n",
    "\n",
    "plt.plot(t_euler, y_euler, 'o-', label='Euler')\n",
    "plt.plot(t_rk4, y_rk4, 's-', label='RK4')\n",
    "plt.plot(t_exact, y_exact, 'k-', label='Exact')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('y(t)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### **19. Solving Linear System with Gaussian Elimination and SciPy**  \n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.linalg import solve, det, norm\n",
    "\n",
    "A = np.array([[3, 2, -1],\n",
    "              [2, -2, 4],\n",
    "              [-1, 0.5, -1]])\n",
    "b = np.array([1, -2, 0])\n",
    "\n",
    "# Gaussian elimination (partial pivoting)\n",
    "def gauss_elimination(A, b):\n",
    "    n = len(b)\n",
    "    for i in range(n):\n",
    "        # Partial pivoting\n",
    "        max_row = np.argmax(np.abs(A[i:, i])) + i\n",
    "        A[[i, max_row]] = A[[max_row, i]]\n",
    "        b[[i, max_row]] = b[[max_row, i]]\n",
    "        \n",
    "        # Elimination\n",
    "        for j in range(i+1, n):\n",
    "            factor = A[j, i] / A[i, i]\n",
    "            A[j, i:] -= factor * A[i, i:]\n",
    "            b[j] -= factor * b[i]\n",
    "    \n",
    "    # Back substitution\n",
    "    x = np.zeros(n)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        x[i] = (b[i] - np.dot(A[i, i+1:], x[i+1:])) / A[i, i]\n",
    "    return x\n",
    "\n",
    "x_gauss = gauss_elimination(A.copy(), b.copy())\n",
    "x_scipy = solve(A, b)\n",
    "\n",
    "print(\"Gaussian Elimination Solution:\", x_gauss)\n",
    "print(\"SciPy Solution:\", x_scipy)\n",
    "\n",
    "# Matrix analysis\n",
    "print(\"Determinant:\", det(A))\n",
    "print(\"Condition Number:\", np.linalg.cond(A))\n",
    "```\n",
    "## **Answer Key for Section D**  \n",
    "\n",
    "### **Multiple Choice Answers**  \n",
    "1. **a) `scipy.optimize.curve_fit()`**  \n",
    "2. **b) The function value and its first derivative**  \n",
    "3. **c) Trapezoidal rule**  \n",
    "4. **b) The coefficients of the polynomial**  \n",
    "5. **d) All of the above**  \n",
    "\n",
    "---\n",
    "\n",
    "### **Short Answer Solutions**  \n",
    "\n",
    "#### **6. Linear Curve Fitting**  \n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def linear_model(x, m, c):\n",
    "    return m * x + c\n",
    "\n",
    "x_data = np.array([0, 1, 2, 3, 4])\n",
    "y_data = np.array([1.0, 1.8, 3.3, 4.5, 6.2])\n",
    "\n",
    "params, _ = curve_fit(linear_model, x_data, y_data)\n",
    "m, c = params\n",
    "\n",
    "x_fit = np.linspace(0, 4, 100)\n",
    "y_fit = linear_model(x_fit, m, c)\n",
    "\n",
    "plt.scatter(x_data, y_data, label='Data')\n",
    "plt.plot(x_fit, y_fit, 'r-', label='Best-fit line')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### **7. Bisection Method Explanation**  \n",
    "- **Method:**  \n",
    "  - Start with an interval $[a, b]$ where $f(a) \\cdot f(b) < 0$.  \n",
    "  - Compute midpoint $c = \\frac{a + b}{2}$.  \n",
    "  - Check the sign of $f(c)$ and update the interval accordingly.  \n",
    "  - Repeat until $|b - a| < \\text{tolerance}$.  \n",
    "- **Advantage:** Guaranteed to converge if $f$ is continuous.\n",
    "- **Disadvantage:** Slower than Newton-Raphson.  \n",
    "\n",
    "---\n",
    "\n",
    "### **8. Root Finding with Newton-Raphson and Bisection**  \n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.optimize import newton, bisect\n",
    "\n",
    "def f(x):\n",
    "    return x**3 - 2*x - 5\n",
    "\n",
    "def df(x):  # Derivative for Newton-Raphson\n",
    "    return 3*x**2 - 2\n",
    "\n",
    "# Newton-Raphson\n",
    "x_newton = newton(f, x0=2, fprime=df, tol=1e-6, maxiter=100)\n",
    "\n",
    "# Bisection\n",
    "x_bisect = bisect(f, a=1, b=3, xtol=1e-6)\n",
    "\n",
    "print(\"Newton-Raphson root:\", x_newton)\n",
    "print(\"Bisection root:\", x_bisect)\n",
    "```\n",
    "\n",
    "**Expected Output:**  \n",
    "- Both methods should converge to **~2.0946**.  \n",
    "- Newton-Raphson typically requires **fewer iterations** than Bisection.  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### **Grading Notes:**  \n",
    "- **Correct implementation** (syntax, logic)  \n",
    "- **Numerical accuracy** (comparison with exact solutions)  \n",
    "- **Proper visualization** (labels, legends, correctness)  \n",
    "- **Explanation of methods** (where required)  \n",
    "\n",
    "### **Grading Scheme for Section D**  \n",
    "- **Multiple Choice:** 2 marks per correct answer.  \n",
    "- **Short Answers:**  \n",
    "  - **Q6:** Correct fitting (3), plotting (2).  \n",
    "  - **Q7:** Explanation (3), advantage/disadvantage (2).  \n",
    "- **Programming Problem:**  \n",
    "  - Correct implementation of both methods (6), comparison (4).  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84eae9-6713-4eb3-8463-1e7fa9547dd2",
   "metadata": {},
   "source": [
    "# Q: Evaluate the integral of $ \\sin(x) $ from $ 0 $ to $ \\pi $ using the **Monte Carlo algorithm**, \n",
    "\n",
    "---\n",
    "\n",
    "### **Mathematical Background**\n",
    "The integral to compute is:\n",
    "$$\n",
    "I = \\int_{0}^{\\pi} \\sin(x) \\, dx\n",
    "$$\n",
    "The exact analytical solution is:\n",
    "$$\n",
    "I = -\\cos(\\pi) - (-\\cos(0)) = 2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Monte Carlo Algorithm (Hit-or-Miss Method)**\n",
    "1. **Define the bounding box**:  \n",
    "   - $ x \\in [0, \\pi] $  \n",
    "   - $ y \\in [0, 1] $ (since $ \\sin(x) \\leq 1 $ in this range).  \n",
    "\n",
    "2. **Generate random points**:  \n",
    "   - Sample $ N $ random points $ (x_i, y_i) $, where:  \n",
    "     $$\n",
    "     x_i \\sim \\text{Uniform}(0, \\pi), \\quad y_i \\sim \\text{Uniform}(0, 1).\n",
    "     $$\n",
    "\n",
    "3. **Count \"hits\" (points under the curve)**:  \n",
    "   - A point $ (x_i, y_i) $ is a \"hit\" if $ y_i \\leq \\sin(x_i) $.  \n",
    "\n",
    "4. **Estimate the integral**:  \n",
    "   - The area under $ \\sin(x) $ is approximated by:  \n",
    "     $$\n",
    "     I \\approx \\left( \\frac{\\text{Number of hits}}{N} \\right) \\times \\text{Total area of bounding box}.\n",
    "     $$\n",
    "   - Here, the bounding box area is $ \\pi \\times 1 = \\pi $, so:  \n",
    "     $$\n",
    "     I \\approx \\left( \\frac{N_{\\text{hits}}}{N} \\right) \\times \\pi.\n",
    "     $$\n",
    "\n",
    "---\n",
    "\n",
    "### **Python Implementation**\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "N = 1_000_000  # Number of samples\n",
    "x = np.random.uniform(0, np.pi, N)  # Random x in [0, π]\n",
    "y = np.random.uniform(0, 1, N)      # Random y in [0, 1]\n",
    "\n",
    "# Count hits (points below sin(x))\n",
    "hits = np.sum(y <= np.sin(x))\n",
    "\n",
    "# Estimate integral\n",
    "integral_estimate = (hits / N) * np.pi\n",
    "print(f\"Monte Carlo estimate: {integral_estimate:.6f}\")\n",
    "```\n",
    "\n",
    "**Output Example** (for $ N = 1,000,000 $):\n",
    "```\n",
    "Monte Carlo estimate: 2.000548\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Observations**\n",
    "1. **Convergence**:  \n",
    "   - As $ N $ increases, the estimate approaches the exact value ($ 2 $).  \n",
    "   - Error scales as $ \\sim 1/\\sqrt{N} $ (typical for Monte Carlo).  \n",
    "\n",
    "2. **Why This Works**:  \n",
    "   - The ratio $ \\frac{N_{\\text{hits}}}{N} $ approximates the fraction of the bounding box area under $ \\sin(x) $.  \n",
    "\n",
    "3. **Alternate Method**:  \n",
    "   - **Mean-value Monte Carlo**:  \n",
    "     $$\n",
    "     I \\approx \\frac{\\pi}{N} \\sum_{i=1}^{N} \\sin(x_i), \\quad x_i \\sim \\text{Uniform}(0, \\pi).\n",
    "     $$\n",
    "     This avoids rejection sampling and is more efficient for 1D integrals.\n",
    "\n",
    "---\n",
    "\n",
    "### **Limitations**\n",
    "- Monte Carlo is inefficient for low-dimensional integrals (trapezoidal or Simpson’s rule would be better here).  \n",
    "- Its strength lies in high-dimensional problems where deterministic methods fail.  \n",
    "\n",
    "For this specific integral, the Monte Carlo method is a pedagogical demonstration rather than a practical choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79617b6c-37ce-4d0c-9dd5-d2c70969139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo estimate: 2.000971\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "N = 1_000_000  # Number of samples\n",
    "x = np.random.uniform(0, np.pi, N)  # Random x in [0, π]\n",
    "y = np.random.uniform(0, 1, N)      # Random y in [0, 1]\n",
    "\n",
    "# Count hits (points below sin(x))\n",
    "hits = np.sum(y <= np.sin(x))\n",
    "\n",
    "# Estimate integral\n",
    "integral_estimate = (hits / N) * np.pi\n",
    "print(f\"Monte Carlo estimate: {integral_estimate:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684ce10-3092-4084-a7d9-68d4172906b0",
   "metadata": {},
   "source": [
    "# Evaluate the integral of $ \\cos(x) $ from $ 0 $ to $ \\pi $ using the **Monte Carlo algorithm**?\n",
    "---\n",
    "### **Mathematical Background**\n",
    "The integral to compute is:\n",
    "$$\n",
    "I = \\int_{0}^{\\pi} \\cos(x) \\, dx\n",
    "$$\n",
    "The exact analytical solution is:\n",
    "$$\n",
    "I = \\sin(\\pi) - \\sin(0) = 0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Monte Carlo Algorithm (Hit-or-Miss Method)**\n",
    "1. **Define the bounding box**:  \n",
    "   - $ x \\in [0, \\pi] $  \n",
    "   - $ y \\in [-1, 1] $ (since $ \\cos(x) $ ranges from $-1$ to $1$ in this interval).  \n",
    "\n",
    "2. **Generate random points**:  \n",
    "   - Sample $ N $ random points $ (x_i, y_i) $, where:  \n",
    "     $$\n",
    "     x_i \\sim \\text{Uniform}(0, \\pi), \\quad y_i \\sim \\text{Uniform}(-1, 1).\n",
    "     $$\n",
    "\n",
    "3. **Count \"hits\" (points under the curve)**:  \n",
    "   - A point $ (x_i, y_i) $ is a \"hit\" if:\n",
    "     - $ y_i \\geq 0 $ and $ y_i \\leq \\cos(x_i) $ (for positive part),  \n",
    "     - **or** $ y_i < 0 $ and $ y_i \\geq \\cos(x_i) $ (for negative part).  \n",
    "\n",
    "4. **Estimate the integral**:  \n",
    "     - The net area under $ \\cos(x) $ is approximated by:\n",
    "  \n",
    "       $$\n",
    "     I \\approx \\left( \\frac{N_{\\text{hits, positive}} - N_{\\text{hits, negative}}}{N} \\right) \\times \\text{Total area of bounding box}.\n",
    "     $$\n",
    "\n",
    "\n",
    "   - Here, the bounding box area is $ \\pi \\times 2 = 2\\pi $, so:  \n",
    "\n",
    "      $$\n",
    "     I \\approx \\left( \\frac{N_{\\text{hits, positive}} - N_{\\text{hits, negative}}}{N} \\right) \\times 2\\pi.\n",
    "     $$\n",
    "\n",
    "---\n",
    "\n",
    "### **Python Implementation**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36795118-9b15-44f6-a093-d2b92bc26dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo estimate: -0.002023\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "N = 1_000_000  # Number of samples\n",
    "x = np.random.uniform(0, np.pi, N)  # Random x in [0, π]\n",
    "y = np.random.uniform(-1, 1, N)     # Random y in [-1, 1]\n",
    "\n",
    "# Count hits for positive and negative parts\n",
    "positive_hits = np.sum((y >= 0) & (y <= np.cos(x)))\n",
    "negative_hits = np.sum((y < 0) & (y >= np.cos(x)))\n",
    "\n",
    "# Estimate integral\n",
    "integral_estimate = (positive_hits - negative_hits) / N * 2 * np.pi\n",
    "print(f\"Monte Carlo estimate: {integral_estimate:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e156e18-96c9-4142-878e-ee8437d0bd6f",
   "metadata": {},
   "source": [
    "### **Key Observations**\n",
    "1. **Symmetry Handling**:  \n",
    "   - The positive and negative contributions cancel out, reflecting the exact result ($ I = 0 $).  \n",
    "\n",
    "2. **Convergence**:  \n",
    "   - The estimate fluctuates around $ 0 $ with error $ \\sim 1/\\sqrt{N} $.  \n",
    "\n",
    "3. **Why This Works**:  \n",
    "   - The net area is computed by balancing positive and negative \"hits\" in the bounding box.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Alternate Method (Mean-Value Monte Carlo)**\n",
    "For efficiency, use the **mean-value method**:\n",
    "$$\n",
    "I \\approx \\frac{\\pi}{N} \\sum_{i=1}^{N} \\cos(x_i), \\quad x_i \\sim \\text{Uniform}(0, \\pi).\n",
    "$$\n",
    "**Python Code**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b703225-78b2-41b8-b46e-11e32471dd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-value estimate: 0.002434\n"
     ]
    }
   ],
   "source": [
    "x = np.random.uniform(0, np.pi, N)\n",
    "integral_estimate = np.pi * np.mean(np.cos(x))\n",
    "print(f\"Mean-value estimate: {integral_estimate:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99374737-fa12-4d66-ac0b-93c6fddd2fe3",
   "metadata": {},
   "source": [
    "### **Discussion**\n",
    "- The hit-or-miss method is less efficient here due to the symmetric cancellation of areas.  \n",
    "- The mean-value method directly averages $ \\cos(x_i) $, avoiding rejection sampling.  \n",
    "- Both methods confirm the theoretical result ($ I = 0 $) but require large $ N $ for precision.  \n",
    "\n",
    "For this integral, deterministic methods (e.g., trapezoidal rule) would be more efficient, but Monte Carlo demonstrates versatility for high-dimensional or complex integrals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e70d2f-c1d9-44a9-b689-410613494cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
